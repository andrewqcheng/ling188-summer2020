{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# pglex--a 'pretty good' lexical service\n",
    "\n",
    "The pglex project seeks to create an API for publishing and retrieving lexical documents, i.e. dictionary entries. The goal is to provide a service that can be used to build dictionary websites and other applications for endangered languages.\n",
    "\n",
    "Other participants: Andrew Garrett, Dmetri Hayes, Edwin Ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The big picture\n",
    "\n",
    "## How things began\n",
    "\n",
    "We wanted to replace the interactive dictionary and text features of the Karuk and Yurok websites created by Andrew Garrett circa 2005.\n",
    "\n",
    "- Performance is mediocre\n",
    "- Difficult to implement certain desired queries\n",
    "- Monolithic -- data files, code, and display are tightly coupled, which makes it difficult to modify and reuse for other language projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The big picture\n",
    "\n",
    "## Our goals\n",
    "\n",
    "Replace the Karuk and Yurok dictionaries in a way that 1) improves the existing dictionaries; and 2) could benefit other language documentation and research projects.\n",
    "\n",
    "- Existing dictionary functions will continue to work\n",
    "- Create a generic solution that will have pretty good results for a wide variety of languages with minimal technical knowledge required of the researcher\n",
    "- Create a service for purposes other than a dictionary website, e.g. language learning tools\n",
    "- Queries\n",
    "  - Allow matches that ignore diacritics (ex. Máíhĩ̵̀kì)\n",
    "  - Allow partial matches\n",
    "  - Morphology-aware searches (for the contact language)\n",
    "    - Search for 'dog' or 'dogs' returns the same result\n",
    "- Provide a basic structure that is pretty good for many languages without restricting what can be in a lexical entry\n",
    "  - Just bring your data!\n",
    "- Faster performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The pglex API\n",
    "\n",
    "An API (Application Progamming Interface) defines interactions between software programs and allows them to communicate in predictable and meaningful ways. For our purposes you can think of the `pglex` API as a set of functions with internet addresses.\n",
    "\n",
    "```\n",
    "# pglex address\n",
    "{base_url}/{project}/{function}\n",
    "\n",
    "base_url = https://q3r0mu6cll.execute-api.us-west-1.amazonaws.com/devapi\n",
    "project = karuk\n",
    "function = lex\n",
    "\n",
    "# The function address\n",
    "https://q3r0mu6cll.execute-api.us-west-1.amazonaws.com/devapi/karuk/lex\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The pglex API\n",
    "\n",
    "## The `lex` function\n",
    "\n",
    "The `lex` function returns a lexical entry based on its identifier. It requires one parameter, the `lexid` that you pass to the function. One way to do this is to add it to the url. Try pasting the following into a web browser's url bar:\n",
    "\n",
    "```\n",
    "https://q3r0mu6cll.execute-api.us-west-1.amazonaws.com/devapi/karuk/lex/4783\n",
    "```\n",
    "\n",
    "Any web browser will do. Firefox is known to format the result nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The pglex API\n",
    "\n",
    "## The `lex` function\n",
    "\n",
    "You can also call the function from a programming language. Here we use the Python [requests library](https://requests.readthedocs.io/en/master/) to access the function and provide the `lexid` parameter in a JSON payload:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "r = requests.post(\n",
    "    'https://q3r0mu6cll.execute-api.us-west-1.amazonaws.com/devapi/karuk/lex',\n",
    "    json={'lexid': ['4783']}\n",
    ")\n",
    "lexes = r.json()['hits']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.post(\n",
    "    'https://q3r0mu6cll.execute-api.us-west-1.amazonaws.com/devapi/karuk/lex',\n",
    "    json={'lexid': ['4783', '4784']}\n",
    ")\n",
    "lexes = r.json()['hits']\n",
    "lexes\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The pglex API\n",
    "\n",
    "## The `q` function\n",
    "\n",
    "The `q` function is used to make a query. This function searches the fields of a lexical entry for a match. It allows a `q` parameter that is used to match a combination of Karuk-language fields or English-language fields.\n",
    "\n",
    "```python\n",
    "r = requests.post(\n",
    "    'https://q3r0mu6cll.execute-api.us-west-1.amazonaws.com/devapi/karuk/q',\n",
    "    json={'q': 'dog'}\n",
    ")\n",
    "lexes = r.json()['hits']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "r = requests.post(\n",
    "    'https://q3r0mu6cll.execute-api.us-west-1.amazonaws.com/devapi/karuk/q',\n",
    "    json={'q': 'dog', 'pf': 10, 'explain': 'true'}\n",
    ")\n",
    "print(r.json()['total'])\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Other possible queries\n",
    "\n",
    "The `q` parameter is not required, and several other parameters can be used to construct a query. A few are illustrated here.\n",
    "\n",
    "```\n",
    "json={'q': '-a', 'flds': 'lex.lo'}  # Search in one specific field\n",
    "json={'q': '-a', 'flds': 'lex.lo^20'}  # Search with a boost\n",
    "json={'sdomain': 'mammal'}             # Filter by semantic domain\n",
    "json={'q': 'dog', 'pos': 'verb'}       # Search for string and filter by part of speech\n",
    "json={'sdomain': 'mammal', 'from': 10, 'size': 2}  # Page through the results\n",
    "json={'sdomain': 'mammal', 'pf': 10, 'from': 0, 'size': 2}   # Popularity factor\n",
    "json={'q': 'dog', 'explain': 'true'}  # The gory details\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using pglex\n",
    "\n",
    "Some sample applications that use `pglex` as a data source.\n",
    "\n",
    "## Karuk dictionary website (Edwin Ko)\n",
    "\n",
    "Karuk dictionary, including example sentences and links to audio recording where available:\n",
    "\n",
    "`http://linguistics.berkeley.edu/scoil_dev_pglex/karuk`\n",
    "\n",
    "## Karuk texts website (Dmetri Hayes)\n",
    "\n",
    "An language-teaching application that contains a set of Karuk texts with audio and that provides detailed lexical information on request:\n",
    "\n",
    "`https://linguistics.berkeley.edu/~dmetri/klamath`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How it works\n",
    "\n",
    "## Elasticsearch\n",
    "\n",
    "Elasticsearch is a document-based database with these features:\n",
    "\n",
    "- Sophisticated indexing for fast queries\n",
    "- Scalable for very large corpora\n",
    "- Flexible JSON documents\n",
    "  - Can define 'pretty good' fields to be maximally useful in searches\n",
    "    - Can ignore diacritics\n",
    "    - Can simplify spellings, e.g. i/ɨ\n",
    "    - Can ignore punctuation\n",
    "  - Multiple values for a field usually okay\n",
    "  - Missing fields in a document are not a problem\n",
    "  - Extra undefined fields are not a problem\n",
    "- Morphological analysis of English (or Spanish or...) fields\n",
    "- Flexible query language\n",
    "  - Calculates 'goodness' of a search result based on relevance\n",
    "  - Can specify fields to search\n",
    "  - Can weight the result by field matched\n",
    "  - Can scale the 'goodness' rating by a field value, e.g. `popcnt`\n",
    "  - Can filter by field\n",
    "  - Partial matches with wildcards\n",
    "  - Regular expression searches (not used by `pglex`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How it works\n",
    "\n",
    "## AWS API Gateway\n",
    "\n",
    "Provides a name (url) for incoming queries and hands them off to AWS Lambda.\n",
    "\n",
    "## AWS Lambda\n",
    "\n",
    "A service for running a 'serverless' function, in our case written in Python. The `q` function:\n",
    "\n",
    "1. Accepts a request sent by the API Gateway.\n",
    "1. Creates an elasticsearch query based on the request parameters.\n",
    "1. Submits the query to our elasticsearch instance.\n",
    "1. Receives the elasticsearch query result.\n",
    "1. Packages the result and sends a response to the requester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with string matching\n",
    "\n",
    "Matching strings can be surprisingly difficult. Why don't the following strings match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "s0 = 'á'\n",
    "s1 = 'á'\n",
    "s0 == s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print the strings in a specific encoding we can see that they contain different bytes. This is because `s0` contains the precomposed character ['LATIN SMALL LETTER A WITH ACUTE'](http://www.fileformat.info/info/unicode/char/00e1/index.htm) and `s1` is the decomposed form with two characters, ['LATIN SMALL LETTER A'](http://www.fileformat.info/info/unicode/char/0061/index.htm) and ['COMBINING ACUTE ACCENT'](http://www.fileformat.info/info/unicode/char/0301/index.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s0.encode('utf8'))\n",
    "print(s1.encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'M á í h ĩ̵̀ k ì'\n",
    "print(s.encode('utf8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
