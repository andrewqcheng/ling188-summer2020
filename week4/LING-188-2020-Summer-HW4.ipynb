{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace the blanks with your full name and collaborators (if any)**\n",
    "\n",
    "Student Name `________________`\n",
    "Collaborator(s) `________________` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Working with SPALEX\n",
    "This assignment is due **Sunday, August 2nd, by 5PM**. Remember to acknowledge above if you collaborated on this assignment with other students.\n",
    "\n",
    "This assignment has 20 points and is worth 7% of your final grade (i.e., it is one of five equally-weighted homework assignments totalling 35% of your grade)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "*Visual word recognition* occurs seemingly effortlessly for readers. However, research has shown that it is affected by words which are *orthographically similar*. When reading the sequence C-A-T, orthographic representations containing those letters are activated. This includes not only CAT, but also CUT, BAT, CAN, CATS and CAST. Generally, words which are orthographically similar to many other words are recognized faster than more distinctive words.\n",
    "\n",
    "But how do we measure orthographic similarity? Part of this assignment will involve computing orthographic similarity via the *number of orthographic neighbors*. This is the number of words which differ by an original word by only one letter (i.e. number of words with a Levenshtein distance of 1).\n",
    "\n",
    "The data you will explore in this assignment is SPALEX, the largest Spanish lexical decision database in the world. It was recently released by [Aguasvivas et al. (2018)](https://www.frontiersin.org/articles/10.3389/fpsyg.2018.02156/full). For the assignment, you will use a small subset of this database that consists of the 20,000 most frequent words.\n",
    "\n",
    "The dataset has the following columns:\n",
    "- *word*: the Spanish word in the standard orthography\n",
    "- *percent_known*: the percent of participants overall who successfully recognized the word\n",
    "- *freq*: the frequency of the word, as obtained from [EsPal](https://www.bcbl.eu/databases/espal/) (These appear to be based on counts of words based on occurences in film subtitles)\n",
    "- *trial_order*: the order in the trial that the participant responded to the word\n",
    "- *rt*: response time, or the amount of time, in milliseconds, it took the participant to respond to the word\n",
    "- *accuracy*: whether or not the participant correctly marked that it was a word\n",
    "\n",
    "Note that the trial orders, reaction times and accuracy values are from different participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up the notebook (1 pt)\n",
    "Run the 2 cells below. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like last week's homework, we are going to be using the `edit_distance` function. As a review, this function has two inputs: `w1` and `w2` (strings) and outputs the *Levenshtein distance* (or *edit distance*) between them (an integer; this is a small change from last time). This is the number of \"edits\" necessary to move from `w1` to `w2`. An edit is either the insertion, deletion or replacement of a letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(w1, w2):\n",
    "    '''Computes the Levenshtein distance between two words.'''\n",
    "    size_x = len(w1) + 1\n",
    "    size_y = len(w2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if w1[x-1] == w2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    # print (matrix) (for debugging purposes)\n",
    "    return int(matrix[size_x - 1, size_y - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in data (5 pts)\n",
    "a. Load \"wk4-spalex.csv\" as a `Table` and name this object `t_full`. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Drop the columns \"trial_order\", \"rt\", and \"accuracy\". (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"percent_known\" column indicates what percent of the participants (n=169,000!) recognized the word. We might expect that low values of \"percent_known\" represent words that are not well established in the Spanish language. Create a new table, `t`, that contains only words recognized by 75% or more of participants. How many words were excluded by filtering operation? What percent of the data does this represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "t = Table.read_table('wk4-spalex.csv')\n",
    "t = t.where('percent_known', are.above(75))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Filtering \"percent_known\" for words recognized by 75% or more participants excluded `___` words. (1 pt)\n",
    "\n",
    "d. In other words, `___` % of the data were excluded. (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. You should still have a table with tens of thousands of rows. Use the method `.sample()` to take a 150-row sample of this Table to work through for the rest of the assignment. Remember to include the argument `with_replacement=False` to avoid repeating rows. Assign this sampled table to `ts`. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute the number of orthographic neighbors (3 pts)\n",
    "\n",
    "An orthographic neighbor is a word that differs from another word by only one letter (i.e., they have an edit distance, or Levenshtein distance, of 1).\n",
    "\n",
    "Create an array `o` which contains the number of orthographic neighbors (from the table `t`) to each of the 150 words in `ts`. Use the `edit_distance` function and a few `for` loops to do this. You may also find it useful to use `np.count_nonzero(x==y)`, a `numpy` function in which `x` is the name of an array, and `y` is a value that you want to count.\n",
    "\n",
    "Remember, you are comparing each word in the randomly-sampled `ts` to *every* word in `t`. Looping through over 10,000 rows 150 times is going to take a while, so I recommend you test your code on a very small subset of `t` before running it all. Including `print()` statements inside your largest loop may also help you keep track of where you are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Print `o` to demonstrate that your computation was successful. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Add your array as a new column in `ts` called \"orth_neighbors\". (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create visualizations (4 pts)\n",
    "\n",
    "a. Create a visualization that illustrates the relationship between \"orth_neighbors\" and \"percent_known\". Include a title and axis labels. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Use `np.polyfit()` with a degree of `1` to determine the slope and intercept of the line of best fit. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Add the line of best fit to your visualization. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. In your own words, describe whether the line of best fit is appropriate for the data. If it is not, how might you change the calculation to get a better-fitting line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your long answer here.* (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conduct statistical tests (3 pts)\n",
    "\n",
    "a. Calculate and report the Pearson's r and Spearman's rho for the correlation between number of orthographic neighbors and \"percent_known\". (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Which measure of correlation is a better measure for the data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your long answer here.* (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. More statistical tests (4 pts)\n",
    "\n",
    "a. For this part of the homework, we will go back to the lexical decision task database from this week's lectures and use it to practice linear modeling and ANOVAs. Read in \"wk4-lexicaldecision.csv\" as a `Table`. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Create a visualization to demonstrate the difference in RT between subjects whose native language was English versus those whose native language was not English (i.e., \"Other\"). Ensure that your ploto has a title and axis labels. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Perform and report the results of an ANOVA to determine whether the difference between native and non-native English speakers is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your long answer here.* (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Be sure to:\n",
    "\n",
    "- save your progress in this notebook\n",
    "- download it to your machine (`File --> Download As --> Notebook (.ipynb)`)\n",
    "- title the document as `HW4_LastName` (e.g. `HW4_Cheng`)\n",
    "- turn it in by uploading it to 'Assignments' on bCourses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
